import streamlit as st
from transformer_lens import HookedTransformer

from attention_pattern import generate_attention_heatmaps
from display_utils import create_svg_html_content
from logits import calculate_all_logits_object_rank, save_all_logits_figures
from model import get_cache, get_output, visualize_model
from prompt import check_answer_correctness, get_random_prompt


@st.cache_resource
def load_model():
    return HookedTransformer.from_pretrained("gpt2-small", device="cpu")


# åˆæœŸè¨­å®š
st.set_page_config(page_title="Visualize LLM Demo", layout="wide")
st.title("Visualize LLM Demo")
model = load_model()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "random_prompt" not in st.session_state:
    st.session_state.random_prompt = ""
if "random_answer" not in st.session_state:
    st.session_state.random_answer = ""

st.markdown("---")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + Random ãƒœã‚¿ãƒ³)
prompt_col1, prompt_col2 = st.columns([4, 1])

with prompt_col1:
    prompt = st.text_input(
        label="ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›ï¼ˆè‹±èªæ¨å¥¨ / è¿·ã£ãŸã‚‰ Random Sample ã‚’ã‚¯ãƒªãƒƒã‚¯ ğŸ‘‰ï¸ï¼‰",
        placeholder="ä¾‹ï¼šSendai is located in the country of",
        value=st.session_state.random_prompt,
        help="ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã™ã‚‹æ–‡ç« ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„",
    )

with prompt_col2:
    st.markdown("<br>", unsafe_allow_html=True)  # ãƒ©ãƒ™ãƒ«åˆ†ã®ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
    if st.button(
        "ğŸ² Random Sample",
        help="ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ç­”ãˆã®ãƒšã‚¢ã‚’ç”Ÿæˆ",
        use_container_width=True,
    ):
        prompt_text, answer_text = get_random_prompt()
        st.session_state.random_prompt = prompt_text
        st.session_state.random_answer = answer_text
        st.rerun()

# ç­”ãˆå…¥åŠ›ã‚¨ãƒªã‚¢ (ç­”ãˆ + Go ãƒœã‚¿ãƒ³)
answer_col1, answer_col2 = st.columns([4, 1])

with answer_col1:
    expected_answer = st.text_input(
        label="âœ… æœŸå¾…ã•ã‚Œã‚‹ç­”ãˆï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ¬¡ã®å˜èª / å…¥åŠ›ã—ãŸã‚‰ Go ã‚’ã‚¯ãƒªãƒƒã‚¯ ğŸš€ï¼‰",
        placeholder="ä¾‹ï¼šJapan",
        value=st.session_state.random_answer,
        help="ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ãŒå‡ºåŠ›ã™ã‚‹ã¨æœŸå¾…ã•ã‚Œã‚‹ç­”ãˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
    )

with answer_col2:
    st.markdown("<br>", unsafe_allow_html=True)  # ãƒ©ãƒ™ãƒ«åˆ†ã®ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
    run = st.button(
        "ğŸš€ Go", help="åˆ†æã‚’é–‹å§‹", use_container_width=True, type="primary"
    )

st.markdown("---")

# ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã ã‘å‡¦ç†ã‚’å®Ÿè¡Œ
if run and prompt:
    # ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ logits ã‚’å–å¾—
    logits, cache = get_cache(model, prompt)

    # ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’å–å¾—
    output = get_output(model, logits)

    # ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    is_correct = check_answer_correctness(model, prompt, logits, expected_answer)

    # å„å±¤ã® logits ã‹ã‚‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é †ä½ã‚’è¨ˆç®—
    object_ranks = calculate_all_logits_object_rank(
        model=model,
        cache=cache,
        prompt=prompt,
        object=expected_answer,
    )

    # è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
    visualization_placeholder = st.empty()

    # ç°¡æ˜“ç‰ˆã® HTML ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¦è¡¨ç¤º (å¾Œç¶šã®å‡¦ç†ã‚’å¾…ã¤é–“ã«è¡¨ç¤º)
    init_path = "figures/graphs/graph_init.svg"
    visualize_model(
        model, filename=init_path, use_urls=False, object_ranks=object_ranks
    )
    max_height = 1000
    margin = 20
    html_content_init = create_svg_html_content(
        init_path,
        max_height=max_height,
        input=prompt,
        output=output,
        is_correct=is_correct,
    )

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«ç°¡æ˜“ç‰ˆã‚’è¡¨ç¤º
    with visualization_placeholder.container():
        st.info(
            "â³ å¯è¦–åŒ–ã‚’ç”Ÿæˆä¸­ã§ã™... ç´„30ç§’ã»ã©å¾…ã¤ã¨ãƒãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°æƒ…å ±ã‚’é–²è¦§ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™"
        )
        st.components.v1.html(
            html_content_init, height=max_height + margin, scrolling=False
        )

    # Attention Pattern ã®ç”Ÿæˆ
    generate_attention_heatmaps(
        model=model,
        cache=cache,
        prompt=prompt,
        output_dir="figures/attention_patterns",
    )

    # logits ã®å¯è¦–åŒ–
    save_all_logits_figures(model, cache)

    # ãƒ¢ãƒ‡ãƒ«ã®å¯è¦–åŒ–
    output_path = "figures/graphs/graph.svg"
    visualize_model(
        model, filename=output_path, use_urls=True, object_ranks=object_ranks
    )

    # å®Œå…¨ç‰ˆã® HTML ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¦ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æ›´æ–°
    html_content_final = create_svg_html_content(
        output_path,
        max_height=max_height,
        input=prompt,
        output=output,
        is_correct=is_correct,
    )

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«å®Œå…¨ç‰ˆã‚’è¡¨ç¤º (ç°¡æ˜“ç‰ˆã‚’ä¸Šæ›¸ã)
    with visualization_placeholder.container():
        st.success(
            "âœ… å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼ãƒãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°æƒ…å ±ã‚’é–²è¦§ã§ãã¾ã™"
        )
        st.components.v1.html(
            html_content_final, height=max_height + margin, scrolling=False
        )
