import streamlit as st
from transformer_lens import HookedTransformer

from attention_pattern import generate_attention_heatmaps
from display_utils import create_svg_html_content
from logits import calculate_all_logits_object_rank, save_all_logits_figures
from model import get_cache, get_output, visualize_model
from prompt import check_answer_correctness, get_random_prompt


@st.cache_resource
def load_model():
    return HookedTransformer.from_pretrained("gpt2-small", device="cpu")


# åˆæœŸè¨­å®š
st.set_page_config(page_title="Visualize LLM Demo", layout="wide")
st.title("Visualize LLM Demo")
model = load_model()

# ãƒ‡ãƒ¢ã®èª¬æ˜
st.markdown("""
### ğŸ§  ã“ã®ãƒ‡ãƒ¢ã«ã¤ã„ã¦

ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€**AIï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ãŒæ¬¡ã®å˜èªã‚’äºˆæ¸¬ã™ã‚‹ä»•çµ„ã¿**ã‚’å¯è¦–åŒ–ã§ãã¾ã™ã€‚

##### ãªãœæ¬¡ã®å˜èªã‚’äºˆæ¸¬ã™ã‚‹ã®ã‹ï¼Ÿ
ChatGPT ã‚„ Google ç¿»è¨³ãªã©ã® AI ã¯ã€ã€Œæ–‡ç« ã®æ¬¡ã®å˜èªã‚’äºˆæ¸¬ã™ã‚‹ã€ã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§æ–‡ç« ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚  
ä¾‹ãˆã°ã€Œç§ã¯æ˜æ—¥ã€å­¦æ ¡ã«ã€ã¨ã„ã†æ–‡ç« ã«å¯¾ã—ã¦ã€AI ã¯ã€Œè¡Œãã€ã€Œå‘ã‹ã†ã€ãªã©ã®é©åˆ‡ãªå˜èªã‚’äºˆæ¸¬ã—ã¾ã™ã€‚  
ã“ã®äºˆæ¸¬ã®ä»•çµ„ã¿ã‚’ç†è§£ã™ã‚‹ã“ã¨ã§ã€AI ãŒã©ã®ã‚ˆã†ã«æ–‡ç« ã‚’ç†è§£ã—ã€ç”Ÿæˆã—ã¦ã„ã‚‹ã‹ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

---

### ğŸ“‹ ä½¿ã„æ–¹
1. æ–‡ç« ã‚’**é€”ä¸­ã¾ã§**å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€ŒSendai is located in the country ofã€ï¼‰
2. **AI ãŒäºˆæ¸¬ã™ã¹ãæ¬¡ã®å˜èª**ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€ŒJapanã€ï¼‰
3. **Go ãƒœã‚¿ãƒ³**ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€AI ã®å†…éƒ¨ã§ã©ã®ã‚ˆã†ã«äºˆæ¸¬ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã‹ãŒå›³ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã¾ã™
4. ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ãŸã‚‰ã€**å›³ã‚’ã‚¯ãƒªãƒƒã‚¯**ã—ã¦è©³ç´°æƒ…å ±ã‚’ç¢ºèªã§ãã¾ã™ï¼ˆ30 ç§’ã»ã©ã‹ã‹ã‚Šã¾ã™ï¼‰

ğŸ’¡ **è¿·ã£ãŸã‚‰ã€ŒRandom Sampleã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ã‚µãƒ³ãƒ—ãƒ«æ–‡ç« ãŒè‡ªå‹•ã§å…¥åŠ›ã•ã‚Œã¾ã™**
""")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "random_prompt" not in st.session_state:
    st.session_state.random_prompt = ""
if "random_answer" not in st.session_state:
    st.session_state.random_answer = ""

st.markdown("---")
st.markdown("### ğŸ“ å…¥åŠ›ã‚¨ãƒªã‚¢")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + Random ãƒœã‚¿ãƒ³)
prompt_col1, prompt_col2 = st.columns([4, 1])

with prompt_col1:
    prompt = st.text_input(
        label="âœï¸ æ–‡ç« ã‚’**é€”ä¸­ã¾ã§**å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆè‹±èªæ¨å¥¨ / è¿·ã£ãŸã‚‰ **Random Sample** ã‚’ã‚¯ãƒªãƒƒã‚¯ ğŸ‘‰ï¸ï¼‰",
        placeholder="ä¾‹ï¼šSendai is located in the country of",
        value=st.session_state.random_prompt,
        help="AI ã«ç¶šãã‚’äºˆæ¸¬ã•ã›ãŸã„æ–‡ç« ã‚’é€”ä¸­ã¾ã§å…¥åŠ›ã—ã¦ãã ã•ã„",
    )

with prompt_col2:
    st.markdown("<br>", unsafe_allow_html=True)  # ãƒ©ãƒ™ãƒ«åˆ†ã®ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
    if st.button(
        "ğŸ² Random Sample",
        help="ã‚µãƒ³ãƒ—ãƒ«æ–‡ç« ã¨ç­”ãˆã‚’è‡ªå‹•ã§å…¥åŠ›ã—ã¾ã™",
        use_container_width=True,
    ):
        prompt_text, answer_text = get_random_prompt()
        st.session_state.random_prompt = prompt_text
        st.session_state.random_answer = answer_text
        st.rerun()

# ç­”ãˆå…¥åŠ›ã‚¨ãƒªã‚¢ (ç­”ãˆ + Go ãƒœã‚¿ãƒ³)
answer_col1, answer_col2 = st.columns([4, 1])

with answer_col1:
    expected_answer = st.text_input(
        label="âœ… AI ãŒäºˆæ¸¬ã™ã¹ã**æ¬¡ã®å˜èª**ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ**å…¥åŠ›ã—ãŸã‚‰ Go ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯** ğŸš€ï¼‰",
        placeholder="ä¾‹ï¼šJapan",
        value=st.session_state.random_answer,
        help="ä¸Šã®æ–‡ç« ã«ç¶šãæ¬¡ã®å˜èªã¨ã—ã¦ã€AI ãŒäºˆæ¸¬ã™ã¹ãæ­£è§£ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
    )

with answer_col2:
    st.markdown("<br>", unsafe_allow_html=True)  # ãƒ©ãƒ™ãƒ«åˆ†ã®ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
    run = st.button(
        "ğŸš€ Go", help="åˆ†æã‚’é–‹å§‹", use_container_width=True, type="primary"
    )

st.markdown("---")

# ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã ã‘å‡¦ç†ã‚’å®Ÿè¡Œ
if run and prompt:
    st.markdown("""
    ### ğŸ”ï¸ AI ã®å†…éƒ¨å¯è¦–åŒ–
    ä¸‹ã®å›³ã¯ AI ã®ã€Œæ€è€ƒéç¨‹ã€ã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚

    **å›³ã®è¦‹æ–¹**  
    ãƒ»**Input**ï¼šå…¥åŠ›ã•ã‚ŒãŸæ–‡ç« ã‚’ **AI ãŒå‡¦ç†ã§ãã‚‹å½¢ã«åŠ å·¥**ã™ã‚‹éƒ¨åˆ†  
    ãƒ»**A0.H0, A1.H1** ãªã©ï¼šã€Œ**ã©ã®å˜èªã«æ³¨ç›®ã™ã¹ãã‹**ã€ã‚’æ±ºã‚ã‚‹å ´æ‰€ï¼ˆAttention å±¤ï¼‰  
    ãƒ»**MLP0, MLP1** ãªã©ï¼šæ³¨ç›®ã—ãŸæƒ…å ±ã‚’ã‚‚ã¨ã«ã€Œ**æ¬¡ã«å‡ºã™å˜èªã®ãƒ’ãƒ³ãƒˆ**ã€ã‚’ä½œã‚‹å ´æ‰€ï¼ˆMLP å±¤ï¼‰  
    ãƒ»**Output**ï¼šğŸ¯ **æœ€çµ‚çš„ãªäºˆæ¸¬çµæœ**ï¼ˆAI ãŒé¸ã¶æ¬¡ã®å˜èªï¼‰ã‚’æ±ºå®šã™ã‚‹éƒ¨åˆ†

    **è‰²ã®æ„å‘³**  
    ãƒ»**ç·‘è‰²ãŒæ¿ƒã„**éƒ¨åˆ†ï¼šå…¥åŠ›ã—ãŸã€ŒæœŸå¾…ã•ã‚Œã‚‹å˜èªã€ã‚’**ä¸Šä½ã§äºˆæ¸¬**ã—ã¦ã„ã‚‹ï¼ˆæ­£è§£ã«è¿‘ã„ï¼‰  
    ãƒ»**ç™½è‰²**ã®éƒ¨åˆ†ï¼šæœŸå¾…ã•ã‚Œã‚‹å˜èªã®**é †ä½ãŒä½ã„**ï¼ˆæ­£è§£ã‹ã‚‰é ã„ï¼‰

    ğŸ’¡ **AI ã¯ä½•ä¸‡ç¨®é¡ã‚‚ã®å˜èªã‹ã‚‰æ¬¡ã®å˜èªã‚’é¸ã‚“ã§ã„ã¾ã™ã€‚ç·‘è‰²ãŒæ¿ƒã„ã»ã©ã€ãã®éƒ¨åˆ†ã§æ­£è§£ã®å˜èªãŒå€™è£œã®ä¸Šä½ã«å…¥ã£ã¦ã„ã¾ã™ã€‚**

    ---

    ### ğŸ“ ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°ã‚’ã¿ã‚‹
    """)

    st.warning("""
    âš ï¸ **å…¨ã¦ã®å‡¦ç†ãŒçµ‚äº†ã—ãŸã‚‰å››è§’ã„ç®±ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã¿ã¦ãã ã•ã„** âš ï¸

    ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€AI ãŒã©ã®å˜èªã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹ã‚„ã€ã©ã®å˜èªã‚’é¸ã³ãã†ã‹ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

    å„å››è§’ã„ç®±ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ä»¥ä¸‹ã®æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™  
    ãƒ»ğŸ“ˆ **æ³¨æ„ãƒ‘ã‚¿ãƒ¼ãƒ³**ï¼šãã®å‡¦ç†éƒ¨åˆ†ãŒã©ã®å˜èªã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹  
    ãƒ»ğŸ† **äºˆæ¸¬ãƒ©ãƒ³ã‚­ãƒ³ã‚°**ï¼šãã®æ™‚ç‚¹ã§ã®å˜èªäºˆæ¸¬ã®é †ä½

    **ğŸ“Š ãŠã™ã™ã‚ï¼šæ¿ƒã„ç·‘è‰²ã®ç®±ã‚’ã‚¯ãƒªãƒƒã‚¯** ğŸ‘ˆï¸ æ­£è§£ã«è¿‘ã„äºˆæ¸¬ã‚’ã—ã¦ã„ã‚‹éƒ¨åˆ†ã®è©³ç´°ãŒè¦‹ã‚‰ã‚Œã¾ã™
    """)

    # ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ logits ã‚’å–å¾—
    logits, cache = get_cache(model, prompt)

    # ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’å–å¾—
    output = get_output(model, logits)

    # ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    is_correct = check_answer_correctness(model, prompt, logits, expected_answer)

    # å„å±¤ã® logits ã‹ã‚‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é †ä½ã‚’è¨ˆç®—
    object_ranks = calculate_all_logits_object_rank(
        model=model,
        cache=cache,
        prompt=prompt,
        object=expected_answer,
    )

    # è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
    visualization_placeholder = st.empty()

    # ç°¡æ˜“ç‰ˆã® HTML ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¦è¡¨ç¤º (å¾Œç¶šã®å‡¦ç†ã‚’å¾…ã¤é–“ã«è¡¨ç¤º)
    init_path = "figures/graphs/graph_init.svg"
    visualize_model(
        model, filename=init_path, use_urls=False, object_ranks=object_ranks
    )
    max_height = 1000
    margin = 20
    html_content_init = create_svg_html_content(
        init_path,
        max_height=max_height,
        input=prompt,
        output=output,
        is_correct=is_correct,
    )

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«ç°¡æ˜“ç‰ˆã‚’è¡¨ç¤º
    with visualization_placeholder.container():
        st.info(
            "â³ å¯è¦–åŒ–ã‚’ç”Ÿæˆä¸­ã§ã™... ç´„ 30 ç§’ã»ã©å¾…ã¤ã¨å››è§’ã„ç®±ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°æƒ…å ±ã‚’é–²è¦§ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™"
        )
        st.components.v1.html(
            html_content_init, height=max_height + margin, scrolling=False
        )

    # Attention Pattern ã®ç”Ÿæˆ
    generate_attention_heatmaps(
        model=model,
        cache=cache,
        prompt=prompt,
        output_dir="figures/attention_patterns",
    )

    # logits ã®å¯è¦–åŒ–
    save_all_logits_figures(model, cache)

    # å®Œå…¨ç‰ˆã® HTML ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¦ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æ›´æ–°
    output_path = "figures/graphs/graph.svg"
    visualize_model(
        model, filename=output_path, use_urls=True, object_ranks=object_ranks
    )
    html_content_final = create_svg_html_content(
        output_path,
        max_height=max_height,
        input=prompt,
        output=output,
        is_correct=is_correct,
    )

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«å®Œå…¨ç‰ˆã‚’è¡¨ç¤º (ç°¡æ˜“ç‰ˆã‚’ä¸Šæ›¸ã)
    with visualization_placeholder.container():
        st.success("ğŸ‰ å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        st.components.v1.html(
            html_content_final, height=max_height + margin, scrolling=False
        )
